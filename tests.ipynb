{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/titeev/diplom/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import MBart50TokenizerFast\n",
    "import pandas as pd\n",
    "from modules.benchmark import GeneratedHeadlinesBenchmark\n",
    "from modules.new_model import My_MBart\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ru-en-RoSBERTa and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bench = GeneratedHeadlinesBenchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/new_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3804, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_metrics(results_list):\n",
    "    aggregated_results = {}\n",
    "\n",
    "    # Проходим по каждому словарю в списке\n",
    "    for result in results_list:\n",
    "        for key, value in result.items():\n",
    "            if isinstance(value, dict):  # Если значение — вложенный словарь\n",
    "                if key not in aggregated_results:\n",
    "                    aggregated_results[key] = {}\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    if sub_key not in aggregated_results[key]:\n",
    "                        aggregated_results[key][sub_key] = []\n",
    "                    aggregated_results[key][sub_key].append(sub_value)\n",
    "            else:  # Если значение — число (метрика)\n",
    "                if key not in aggregated_results:\n",
    "                    aggregated_results[key] = []\n",
    "                aggregated_results[key].append(value)\n",
    "\n",
    "    # Усредняем все числовые значения\n",
    "    for key in aggregated_results:\n",
    "        if isinstance(aggregated_results[key], dict):  # Вложенный словарь\n",
    "            for sub_key in aggregated_results[key]:\n",
    "                aggregated_results[key][sub_key] = np.mean(aggregated_results[key][sub_key])\n",
    "        else:\n",
    "            aggregated_results[key] = np.mean(aggregated_results[key])\n",
    "\n",
    "    return aggregated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_markdown(data, model_name):\n",
    "    # Извлекаем все ключи\n",
    "    headers = []\n",
    "    values = []\n",
    "    \n",
    "    # Заполняем данные\n",
    "    for key, value in data.items():\n",
    "        # if isinstance(value, dict):\n",
    "        #     for sub_key, sub_value in value.items():\n",
    "        #         headers.append(f\"{key} - {sub_key}\")\n",
    "        #         values.append(f\"{sub_value['mean']:.6f} +- {sub_value['std']:.6f}\")\n",
    "        # else:\n",
    "        headers.append(key)\n",
    "        values.append(f\"{value['mean']:.6f} +- {value['std']:.6f}\")\n",
    "    \n",
    "    # Формируем таблицу\n",
    "    markdown_table = \"| Model | \" + \" | \".join(headers) + \" |\\n\"\n",
    "    markdown_table += \"| ----- | \" + \" | \".join([\"-\" * len(h) for h in headers]) + \" |\\n\"\n",
    "    markdown_table += \"| \" + model_name + \"| \" + \" | \".join(values) + \" |\\n\"\n",
    "    \n",
    "    return markdown_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(metrics_list):\n",
    "    # Соберем все значения по ключам\n",
    "    aggregated = defaultdict(list)\n",
    "\n",
    "    for metrics in metrics_list:\n",
    "        for k, v in metrics['Rouge'].items():\n",
    "            aggregated[k].append(v)\n",
    "        aggregated['Meteor'].append(metrics['Meteor'])\n",
    "        aggregated['Cider'].append(metrics['Cider'])\n",
    "        for k, v in metrics['CS_CR'].items():\n",
    "            aggregated[k].append(v)\n",
    "\n",
    "    # Посчитаем mean и std\n",
    "    results = {}\n",
    "    for key, values in aggregated.items():\n",
    "        values_np = np.array(values)\n",
    "        results[key] = {\n",
    "            'mean': float(np.mean(values_np)),\n",
    "            'std': float(np.std(values_np))\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = pd.read_csv('./data/cluster_centers_new.csv')\n",
    "cluster_centers = cluster_centers.drop('cluster_id', axis=1)\n",
    "cluster_centers = cluster_centers.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_metadata(cluster_id):\n",
    "    cluster_info = f\"Кластер: {cluster_id} | Ключевые слова: {', '.join(cluster_keyword[cluster_id])}\"\n",
    "    return cluster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3804it [17:59,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_seed_metrics = []\n",
    "for seed in seeds:\n",
    "    model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_baseline_seed{seed}\")\n",
    "    model = model.to('cuda')\n",
    "    results = []\n",
    "    for text, title in tqdm(zip(test_data['text'], test_data['title'])):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            max_length=600,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # print(inputs['input_ids'])\n",
    "        output = model.generate(\n",
    "            input_ids=inputs['input_ids'].to('cuda'),\n",
    "            attention_mask=inputs['attention_mask'].to('cuda'),\n",
    "            max_length=128,\n",
    "        )\n",
    "        \n",
    "        headline = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        results.append(bench.calculate_metrics(text, title, headline))\n",
    "    average_results = average_metrics(results)\n",
    "    baseline_seed_metrics.append(average_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': {'mean': 0.16395110958435435, 'std': 0.0},\n",
       " 'ROUGE-2': {'mean': 0.0782541440047328, 'std': 0.0},\n",
       " 'ROUGE-L': {'mean': 0.15795206982475365, 'std': 0.0},\n",
       " 'Meteor': {'mean': 0.1425000390236755, 'std': 0.0},\n",
       " 'Cider': {'mean': 0.11578667793528173, 'std': 0.0},\n",
       " 'Cosine Similarity': {'mean': 0.6182661373109472, 'std': 0.0},\n",
       " 'Conseptual Relevance': {'mean': 0.9492792911008197, 'std': 0.0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std(baseline_seed_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Meteor | Cider | Cosine Similarity | Conseptual Relevance |\n",
      "| ----- | ------- | ------- | ------- | ------ | ----- | ----------------- | -------------------- |\n",
      "| baseline| 0.163951 +- 0.000000 | 0.078254 +- 0.000000 | 0.157952 +- 0.000000 | 0.142500 +- 0.000000 | 0.115787 +- 0.000000 | 0.618266 +- 0.000000 | 0.949279 +- 0.000000 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_markdown(mean_std(baseline_seed_metrics), 'baseline'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inject cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inject cluster type 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_3694767/2521284818.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
      "3804it [18:11,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_metrics = []\n",
    "for seed in seeds:\n",
    "    model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_0_seed{seed}\")\n",
    "    model = model.to('cuda')\n",
    "    results = []\n",
    "    for text, cluster, title in tqdm(zip(test_data['text'], test_data['cluster'], test_data['title'])):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            max_length=600,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids=inputs['input_ids'].to('cuda'),\n",
    "            attention_mask=inputs['attention_mask'].to('cuda'),\n",
    "            meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
    "            max_length=128,\n",
    "        )\n",
    "        \n",
    "        headline = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        results.append(bench.calculate_metrics(text, title, headline))\n",
    "    average_results = average_metrics(results)\n",
    "    seed_metrics.append(average_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': {'mean': 0.15068339673212125, 'std': 0.0},\n",
       " 'ROUGE-2': {'mean': 0.06754238706297275, 'std': 0.0},\n",
       " 'ROUGE-L': {'mean': 0.14554023039671127, 'std': 0.0},\n",
       " 'Meteor': {'mean': 0.12777954331616564, 'std': 0.0},\n",
       " 'Cider': {'mean': 0.10057767049087663, 'std': 0.0},\n",
       " 'Cosine Similarity': {'mean': 0.6027991571762333, 'std': 0.0},\n",
       " 'Conseptual Relevance': {'mean': 0.9345790706864956, 'std': 0.0}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std(seed_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Meteor | Cider | Cosine Similarity | Conseptual Relevance |\n",
      "| ----- | ------- | ------- | ------- | ------ | ----- | ----------------- | -------------------- |\n",
      "| add_cluster_type_0| 0.150683 +- 0.000000 | 0.067542 +- 0.000000 | 0.145540 +- 0.000000 | 0.127780 +- 0.000000 | 0.100578 +- 0.000000 | 0.602799 +- 0.000000 | 0.934579 +- 0.000000 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_markdown(mean_std(seed_metrics), 'add_cluster_type_0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inject cluster type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_3705788/1929946156.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
      "3804it [17:06,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_metrics_1 = []\n",
    "for seed in seeds:\n",
    "    model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_1_seed{seed}\")\n",
    "    model = model.to('cuda')\n",
    "    results = []\n",
    "    for text, cluster, title in tqdm(zip(test_data['text'], test_data['cluster'], test_data['title'])):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            max_length=600,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids=inputs['input_ids'].to('cuda'),\n",
    "            attention_mask=inputs['attention_mask'].to('cuda'),\n",
    "            meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
    "            max_length=128,\n",
    "        )\n",
    "        \n",
    "        headline = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        results.append(bench.calculate_metrics(text, title, headline))\n",
    "    average_results = average_metrics(results)\n",
    "    seed_metrics_1.append(average_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': {'mean': 0.18111516029655053, 'std': 0.0},\n",
       " 'ROUGE-2': {'mean': 0.09009259794078926, 'std': 0.0},\n",
       " 'ROUGE-L': {'mean': 0.17393819945544725, 'std': 0.0},\n",
       " 'Meteor': {'mean': 0.16055247105241818, 'std': 0.0},\n",
       " 'Cider': {'mean': 0.13565889822174085, 'std': 0.0},\n",
       " 'Cosine Similarity': {'mean': 0.6338736785793154, 'std': 0.0},\n",
       " 'Conseptual Relevance': {'mean': 0.9587906478409188, 'std': 0.0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std(seed_metrics_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Meteor | Cider | Cosine Similarity | Conseptual Relevance |\n",
      "| ----- | ------- | ------- | ------- | ------ | ----- | ----------------- | -------------------- |\n",
      "| add_cluster_type_1| 0.181115 +- 0.000000 | 0.090093 +- 0.000000 | 0.173938 +- 0.000000 | 0.160552 +- 0.000000 | 0.135659 +- 0.000000 | 0.633874 +- 0.000000 | 0.958791 +- 0.000000 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_markdown(mean_std(seed_metrics_1), 'add_cluster_type_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inject cluster type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3804it [19:24,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_metrics_2 = []\n",
    "for seed in seeds:\n",
    "    model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_2_seed{seed}\")\n",
    "    model = model.to('cuda')\n",
    "    results = []\n",
    "    for text, cluster, title in tqdm(zip(test_data['text'], test_data['cluster'], test_data['title'])):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            max_length=600,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids=inputs['input_ids'].to('cuda'),\n",
    "            attention_mask=inputs['attention_mask'].to('cuda'),\n",
    "            meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
    "            max_length=128,\n",
    "        )\n",
    "        \n",
    "        headline = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        results.append(bench.calculate_metrics(text, title, headline))\n",
    "    average_results = average_metrics(results)\n",
    "    seed_metrics_2.append(average_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': {'mean': 0.18546602598337764, 'std': 0.0},\n",
       " 'ROUGE-2': {'mean': 0.09422155396520057, 'std': 0.0},\n",
       " 'ROUGE-L': {'mean': 0.17835019975468192, 'std': 0.0},\n",
       " 'Meteor': {'mean': 0.1635646489625219, 'std': 0.0},\n",
       " 'Cider': {'mean': 0.14005738312127403, 'std': 0.0},\n",
       " 'Cosine Similarity': {'mean': 0.6372775763320246, 'std': 0.0},\n",
       " 'Conseptual Relevance': {'mean': 0.9606065979546671, 'std': 0.0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std(seed_metrics_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Meteor | Cider | Cosine Similarity | Conseptual Relevance |\n",
      "| ----- | ------- | ------- | ------- | ------ | ----- | ----------------- | -------------------- |\n",
      "| add_cluster_type_2| 0.185466 +- 0.000000 | 0.094222 +- 0.000000 | 0.178350 +- 0.000000 | 0.163565 +- 0.000000 | 0.140057 +- 0.000000 | 0.637278 +- 0.000000 | 0.960607 +- 0.000000 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_markdown(mean_std(seed_metrics_2), 'add_cluster_type_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inject cluster type 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3804it [18:12,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_metrics_3 = []\n",
    "for seed in seeds:\n",
    "    model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_3_seed{seed}\")\n",
    "    model = model.to('cuda')\n",
    "    results = []\n",
    "    for text, cluster, title in tqdm(zip(test_data['text'], test_data['cluster'], test_data['title'])):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            max_length=600,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids=inputs['input_ids'].to('cuda'),\n",
    "            attention_mask=inputs['attention_mask'].to('cuda'),\n",
    "            meta_embs=torch.Tensor([cluster_centers[cluster]]).to('cuda'),\n",
    "            max_length=128,\n",
    "        )\n",
    "        \n",
    "        headline = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        results.append(bench.calculate_metrics(text, title, headline))\n",
    "    average_results = average_metrics(results)\n",
    "    seed_metrics_3.append(average_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROUGE-1': {'mean': 0.1676581930189058, 'std': 0.0},\n",
       " 'ROUGE-2': {'mean': 0.08088196856463964, 'std': 0.0},\n",
       " 'ROUGE-L': {'mean': 0.1614964434334131, 'std': 0.0},\n",
       " 'Meteor': {'mean': 0.14532582525254809, 'std': 0.0},\n",
       " 'Cider': {'mean': 0.11850514268053758, 'std': 0.0},\n",
       " 'Cosine Similarity': {'mean': 0.6196152599906445, 'std': 0.0},\n",
       " 'Conseptual Relevance': {'mean': 0.9494767407316153, 'std': 0.0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std(seed_metrics_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Meteor | Cider | Cosine Similarity | Conseptual Relevance |\n",
      "| ----- | ------- | ------- | ------- | ------ | ----- | ----------------- | -------------------- |\n",
      "| add_cluster_type_3| 0.167658 +- 0.000000 | 0.080882 +- 0.000000 | 0.161496 +- 0.000000 | 0.145326 +- 0.000000 | 0.118505 +- 0.000000 | 0.619615 +- 0.000000 | 0.949477 +- 0.000000 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_markdown(mean_std(seed_metrics_3), 'add_cluster_type_3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ручные тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = My_MBart.from_pretrained(\"models/ft-bart-headline-generation_baseline_seed42\")\n",
    "baseline_model = baseline_model.to('cuda')\n",
    "\n",
    "add_cluster_0_model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_0_seed42\")\n",
    "add_cluster_0_model = add_cluster_0_model.to('cuda')\n",
    "\n",
    "add_cluster_1_model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_1_seed42\")\n",
    "add_cluster_1_model = add_cluster_1_model.to('cuda')\n",
    "\n",
    "add_cluster_2_model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_2_seed42\")\n",
    "add_cluster_2_model = add_cluster_2_model.to('cuda')\n",
    "\n",
    "add_cluster_3_model = My_MBart.from_pretrained(f\"models/ft-bart-headline-generation_add_cluster_3_seed42\")\n",
    "add_cluster_3_model = add_cluster_3_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«Слабее умом»: в РПЦ рассказали об отношении к...</td>\n",
       "      <td>Большинство мужчин умнее женщин — такое мнение...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Стажировка в JetBrains и как мне почти удалось...</td>\n",
       "      <td>Как и многие молодые разработчики, когда появл...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Угроза Меркель: мигранты раскололи правительст...</td>\n",
       "      <td>В блоке партий «Христианско-демократический со...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 слова, досуг и свободные номера</td>\n",
       "      <td>Banjo в Google Play цена: бесплатно После успе...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Газ — по расписанию</td>\n",
       "      <td>Обострение российско-украинского конфликта ста...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>Евросоюзу показали «синий язык»</td>\n",
       "      <td>Европейский союз пожаловался в ВТО на ряд прот...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>С моцартианской легкостью по красной дорожке</td>\n",
       "      <td>Само появление имени Брука в афише NET многих ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>Гонят из России? Алсу в мечтах об украинском т...</td>\n",
       "      <td>Популярная российская певица Алсу сделала гром...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>Одноразовый преемник</td>\n",
       "      <td>Экс-кандидат в президенты Южной Осетии Анатоли...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>«Автобус задел фуру по касательной»</td>\n",
       "      <td>Четыре человека погибли и еще 25 получили разл...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3804 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     «Слабее умом»: в РПЦ рассказали об отношении к...   \n",
       "1     Стажировка в JetBrains и как мне почти удалось...   \n",
       "2     Угроза Меркель: мигранты раскололи правительст...   \n",
       "3                     3 слова, досуг и свободные номера   \n",
       "4                                   Газ — по расписанию   \n",
       "...                                                 ...   \n",
       "3799                    Евросоюзу показали «синий язык»   \n",
       "3800       С моцартианской легкостью по красной дорожке   \n",
       "3801  Гонят из России? Алсу в мечтах об украинском т...   \n",
       "3802                               Одноразовый преемник   \n",
       "3803                «Автобус задел фуру по касательной»   \n",
       "\n",
       "                                                   text  cluster  \n",
       "0     Большинство мужчин умнее женщин — такое мнение...       19  \n",
       "1     Как и многие молодые разработчики, когда появл...        8  \n",
       "2     В блоке партий «Христианско-демократический со...        0  \n",
       "3     Banjo в Google Play цена: бесплатно После успе...       19  \n",
       "4     Обострение российско-украинского конфликта ста...        6  \n",
       "...                                                 ...      ...  \n",
       "3799  Европейский союз пожаловался в ВТО на ряд прот...        6  \n",
       "3800  Само появление имени Брука в афише NET многих ...        1  \n",
       "3801  Популярная российская певица Алсу сделала гром...       14  \n",
       "3802  Экс-кандидат в президенты Южной Осетии Анатоли...        0  \n",
       "3803  Четыре человека погибли и еще 25 получили разл...       20  \n",
       "\n",
       "[3804 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_titles(idx):\n",
    "    prompt_inputs = tokenizer(\n",
    "        [test_data.iloc[idx].text],\n",
    "        max_length=1024,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    default_inputs = tokenizer(\n",
    "        [test_data.iloc[idx].text],\n",
    "        max_length=1024,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    baseline_output_ids = baseline_model.generate(\n",
    "        input_ids=default_inputs['input_ids'].to('cuda'),\n",
    "        attention_mask=default_inputs['attention_mask'].to('cuda'),\n",
    "        max_length=128\n",
    "    )[0]\n",
    "\n",
    "    type_0_ids = add_cluster_0_model.generate(\n",
    "        input_ids=default_inputs['input_ids'].to('cuda'),\n",
    "        attention_mask=default_inputs['attention_mask'].to('cuda'),\n",
    "        meta_embs=torch.Tensor([cluster_centers[test_data.iloc[idx].cluster]]).to('cuda'),\n",
    "        max_length=128\n",
    "    )[0]\n",
    "\n",
    "    type_1_ids = add_cluster_1_model.generate(\n",
    "        input_ids=default_inputs['input_ids'].to('cuda'),\n",
    "        attention_mask=default_inputs['attention_mask'].to('cuda'),\n",
    "        meta_embs=torch.Tensor([cluster_centers[test_data.iloc[idx].cluster]]).to('cuda'),\n",
    "        max_length=128\n",
    "    )[0]\n",
    "\n",
    "    type_2_ids = add_cluster_2_model.generate(\n",
    "        input_ids=default_inputs['input_ids'].to('cuda'),\n",
    "        attention_mask=default_inputs['attention_mask'].to('cuda'),\n",
    "        meta_embs=torch.Tensor([cluster_centers[test_data.iloc[idx].cluster]]).to('cuda'),\n",
    "        max_length=128\n",
    "    )[0]\n",
    "\n",
    "    type_3_ids = add_cluster_3_model.generate(\n",
    "        input_ids=default_inputs['input_ids'].to('cuda'),\n",
    "        attention_mask=default_inputs['attention_mask'].to('cuda'),\n",
    "        meta_embs=torch.Tensor([cluster_centers[test_data.iloc[idx].cluster]]).to('cuda'),\n",
    "        max_length=128\n",
    "    )[0]\n",
    "\n",
    "    # headline = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    print(\"Generated headlines:\")\n",
    "    print(\"\\tBaseline:\", tokenizer.decode(baseline_output_ids, skip_special_tokens=True))\n",
    "    print(\"\\tType 0:\", tokenizer.decode(type_0_ids, skip_special_tokens=True))\n",
    "    print(\"\\tType 1:\", tokenizer.decode(type_1_ids, skip_special_tokens=True))\n",
    "    print(\"\\tType 2:\", tokenizer.decode(type_2_ids, skip_special_tokens=True))\n",
    "    print(\"\\tType 3:\", tokenizer.decode(type_3_ids, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated headlines:\n",
      "\tBaseline: Адоболи обманул боссов\n",
      "\tType 0: «У него есть чутье»: как Адоболи обманул боссов\n",
      "\tType 1: Убийца UBS попал под домашний арест\n",
      "\tType 2: Убийца UBS попал под домашний арест\n",
      "\tType 3: Адоболи обманул боссов\n",
      "True headline: «Хаос и несчастье для себя и для всех»\n"
     ]
    }
   ],
   "source": [
    "idx = 1831\n",
    "gen_titles(idx)\n",
    "print(\"True headline:\", test_data.iloc[idx].title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
